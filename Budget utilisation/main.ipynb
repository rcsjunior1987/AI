{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d7c375635162da09f0df265be1ff543fa0e54d4b5ed0ee516c18eaf6e6e8fe7a",
   "display_name": "Python 3.8.5 32-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "d7c375635162da09f0df265be1ff543fa0e54d4b5ed0ee516c18eaf6e6e8fe7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- LIBRARIES NECESSARY IN THIS PROJECT  -------------------------- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import *\n",
    "import zipfile\n",
    "\n",
    "# -------------------------- FUNCTIONS -------------------------- #\n",
    "\n",
    "def getDataSet(data_path):\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def plotNaNValuesColums(dataSet):\n",
    "    # Gets the dataSet Columns with null values\n",
    "    #  and the Percentual of null values per column    \n",
    "    missing_values = (dataSet.isnull().sum() / len(dataSet)) * 100    \n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    missing_values.sort_values(inplace=True)   \n",
    "\n",
    "    missing_values = missing_values.to_frame()\n",
    "    missing_values.columns = ['Percentual']\n",
    "    missing_values.index.names = ['Name']\n",
    "    missing_values['Column'] = missing_values.index\n",
    "\n",
    "    # Plots the graph\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x = 'Column', y = 'Percentual', data=missing_values)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    print(missing_values)\n",
    "    \n",
    "def plotNotNaNValuesColums(dataSet):\n",
    "    # Gets the dataSet Columns with null values\n",
    "    #  and the Percentual of null values per column    \n",
    "    missing_values = (dataSet.notnull().sum() / len(dataSet)) * 100    \n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    missing_values.sort_values(inplace=True)   \n",
    "\n",
    "    missing_values = missing_values.to_frame()\n",
    "    missing_values.columns = ['Percentual']\n",
    "    missing_values.index.names = ['Name']\n",
    "    missing_values['Column'] = missing_values.index\n",
    "\n",
    "    # Plots the graph\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x = 'Column', y = 'Percentual', data=missing_values)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "    print(missing_values) "
   ]
  },
  {
   "source": [
    "## Upload dataSets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- PATH OF THE DATASETS USED IN THE PROJECT  -------------------------- #\n",
    "zf = zipfile.ZipFile('dataSets.zip')\n",
    "\n",
    "invoices_claims_last_actived_all_fields = pd.read_csv(zf.open('Invoices_Claims_Last_Actived.csv'))\n",
    "invoices_claims_last_completed_all_fields = pd.read_csv(zf.open('Invoices_Claims_Last_Completed.csv'))\n",
    "plans_budgets_all_fields = pd.read_csv(zf.open('Plans_Budgets.csv'))\n",
    "members_supported_all_fields = pd.read_csv(zf.open('Members_Supported.csv')) \n",
    "providers_all_fields = pd.read_csv(zf.open('Providers.csv'))"
   ]
  },
  {
   "source": [
    "## Data manipulation and cleansing<a name=\"preparation\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Members dataset cleasing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataSet fields\n",
    "members_supported_all_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_supported_all_fields.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the fields to be used\n",
    "df_members_supported = members_supported_all_fields[{\"id\"\n",
    "                                                   , \"member_key\" \n",
    "                                                   , \"first_name\"\n",
    "                                                   , \"last_name\"\n",
    "                                                   , \"price_zone_code\"\n",
    "                                                   , \"u_disabilities\"\n",
    "                                                   , \"SA1\"\n",
    "                                                   }]\n",
    "\n",
    "# Rename some dataSet colums to create a name's pattern\n",
    "df_members_supported.rename(columns={'id':'member_id'\n",
    "                                   , 'u_disabilities':'disabilities'\n",
    "                                    } , inplace = True)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any NaN Field\n",
    "plotNaNValuesColums(df_members_supported)\n",
    "\n",
    "# Although amount of null values in the columns is high they are keeped in the dataSet\n",
    "#  And it is assigned 'Not Assigned' to the null values in u_disabilities and SA1\n",
    "df_members_supported.loc[df_members_supported['disabilities'].isnull(),['disabilities']] = \"Not Assigned\"\n",
    "df_members_supported.loc[df_members_supported['SA1'].isnull(),['SA1']] = \"Not Assigned\"\n",
    "\n",
    "df_members_cleased = df_members_supported"
   ]
  },
  {
   "source": [
    "### Plans and budgets dataset cleasing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataSet fields\n",
    "plans_budgets_all_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plans_budgets_all_fields.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the fields to be used\n",
    "df_plans_budgets = plans_budgets_all_fields[{\"member_key\"\n",
    "                                           , \"plan_key\"\n",
    "                                           , \"plan_start_date\" \n",
    "                                           , \"plan_start_date.1\"\n",
    "                                           , \"status\"\n",
    "                                           , \"budget_number\"                                              \n",
    "                                           , \"level2_key\"\n",
    "                                           , \"level2_name\"\n",
    "                                           , \"level1_key\"\n",
    "                                           , \"level1_name\"\n",
    "                                           , \"item_category_level3_key\"\n",
    "                                           , \"budget_level3_name\"\n",
    "                                           , \"opening_balance\"\n",
    "                                           , \"closing_balance\"\n",
    "                                           , \"value_allocated_budget\"\n",
    "                                           , \"status_budget\"\n",
    "                                           }]\n",
    "\n",
    "\n",
    "# Rename some dataSet colums to create a name's pattern\n",
    "df_plans_budgets.rename(columns={'plan_start_date.1':'plan_end_date'\n",
    "                               , 'status':'plan_status'                               \n",
    "                               , 'status_budget':'budget_status'\n",
    "                               , 'value_allocated_budget':'budget_amount'\n",
    "                               , 'level2_key':'budget_level2_key'\n",
    "                               , 'level2_name':'budget_level2_name'\n",
    "                               , 'level2_display_name':'budget_level2_display_name'\n",
    "                               , 'level1_key':'budget_level1_key'\n",
    "                               , 'level1_name':'budget_level1_name'\n",
    "                               , 'item_category_level3_key':'budget_level3_key'\n",
    "                               , 'level3_reference_number':'budget_level3_reference_number'                               \n",
    "                                } , inplace = True)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Budget's status in the dataSet\n",
    "np.unique(df_plans_budgets['budget_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any Nan Field\n",
    "print(plotNaNValuesColums(df_plans_budgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some budget_number NaN Data to\n",
    "#  Check these data have in commum\n",
    "#   It is seen that when budget_number is null\n",
    "#    opening_balance and closing_balance are not null\n",
    "Null_budget_number = df_plans_budgets.loc[(df_plans_budgets['budget_number'].isna())]\n",
    "Null_budget_number.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some budget_number Not NaN Data to\n",
    "#  Check these data have in commum\n",
    "#   It is seen that when budget_number is null\n",
    "#    opening_balance and closing_balance are null\n",
    "Null_budget_number = df_plans_budgets.loc[(df_plans_budgets['budget_number'].notna())]\n",
    "Null_budget_number.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentual of opening_balance and closing_balance not Nan with budget_number Nan\n",
    "Null_budget_number = df_plans_budgets[{'opening_balance', 'closing_balance'}].loc[(df_plans_budgets['budget_number'].isna())]\n",
    "plotNotNaNValuesColums(Null_budget_number)\n",
    "\n",
    "# Deletes the records with budget_number are NaN\n",
    "#  As They are rows that represents Balance\n",
    "df_plans_budgets = df_plans_budgets.drop(df_plans_budgets[df_plans_budgets.budget_number.isna()].index)\n",
    "\n",
    "#  And keeps the ones with level3_reference_number, stated_item_name, level3_key\n",
    "#   Assigns 'Not Assigned' in columns 'level3_key','level3_reference_number', 'stated_item_name'\n",
    "#   because if budget_level3_key, level3_key are NaN\n",
    "#   Means the budget starts in level 2\n",
    "df_plans_budgets.loc[df_plans_budgets['budget_level3_key'].isnull(),['budget_level3_key', 'budget_level3_name']] = \"Not Assigned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any DateTime column\n",
    "df_plans_budgets.select_dtypes(include=[np.datetime64]).any().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plans_budgets['plan_start_date'] = pd.to_datetime(df_plans_budgets['plan_start_date']).dt.strftime('%Y-%m-%d')\n",
    "df_plans_budgets['plan_end_date'] = pd.to_datetime(df_plans_budgets['plan_end_date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the plans from their bugdets\n",
    "df_plans_budgets_cleased = df_plans_budgets.groupby([\"member_key\"\n",
    "                                                   , \"plan_key\"\n",
    "                                                   , \"plan_status\"\n",
    "                                                   , \"plan_start_date\"\n",
    "                                                   , \"plan_end_date\"\n",
    "                                                   , \"budget_status\"\n",
    "                                                   , \"budget_level3_name\"\n",
    "                                                   , \"budget_level3_key\" \n",
    "                                                   , \"budget_level2_key\"\n",
    "                                                   , \"budget_level2_name\"\n",
    "                                                   , \"budget_level1_key\"\n",
    "                                                   , \"budget_level1_name\"]).agg({\"budget_amount\": \"sum\"}).reset_index()                                                   "
   ]
  },
  {
   "source": [
    "### Invoice and claims dataset cleasing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Invoice and claims dataset From LAST ACTIVED plan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataSet fields\n",
    "invoices_claims_last_actived_all_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_actived_all_fields.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the fields to be used\n",
    "invoices_claims_last_actived = invoices_claims_last_actived_all_fields[{\"member_id\"\n",
    "                                                                      , \"invoice_state\"\n",
    "                                                                      , \"invoice_id\"\n",
    "                                                                      , \"updated_at\"\n",
    "                                                                      , \"claim_state\"\n",
    "                                                                      , \"claim_id\"\n",
    "                                                                      , \"key\"  \n",
    "                                                                      , \"key.1\"\n",
    "                                                                      , \"key.2\"\n",
    "                                                                      , \"claim_start_date\"\n",
    "                                                                      , \"claim_end_date\"\n",
    "                                                                      , \"claim_funded_amount\"\n",
    "                                                                      , \"invoiced_amount\"\n",
    "                                                                      , \"claimed_units\"\n",
    "                                                                      , \"claimed_unit_price\"\n",
    "                                                                     }]\n",
    "\n",
    "# Rename some dataSet colums to create a name's pattern\n",
    "invoices_claims_last_actived.rename(columns={'claim_funded_amount':'funded_amount'                                           \n",
    "                                           , 'claimed__units_price':'claimed__units_amount'  \n",
    "                                           , 'key.1':'claim_level2_key'\n",
    "                                           , 'key.2':'claim_level1_key'\n",
    "                                           , 'key':'claim_level3_key'\n",
    "                                              } , inplace = True)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the claim_state To check whether there is any dump value\n",
    "invoices_claims_last_actived['claim_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_actived = invoices_claims_last_actived.drop(invoices_claims_last_actived[invoices_claims_last_actived.invoice_state.isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the claim_state To check whether there is any dump value\n",
    "invoices_claims_last_actived['invoice_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_actived['claim_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any Nan Field\n",
    "print(plotNaNValuesColums(invoices_claims_last_actived))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some invoiced_amount and invoiced_amount NaN Data to\n",
    "#  Check these data have in commum\n",
    "df_invoiced_units_NaN = invoices_claims_last_actived.loc[invoices_claims_last_actived['funded_amount'].isna()]\n",
    "df_invoiced_units_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the state of invoice and claim of all null data\n",
    "#  And Keeps these records\n",
    "#   Because if 'funded_amount' is NaN means the claims is not PAID OR REFUNDED\n",
    "df_invoiced_units_NaN[{\"invoice_state\"\n",
    "                     , \"claim_state\"\n",
    "                      }].groupby([\"invoice_state\"\n",
    "                                , \"claim_state\"\n",
    "                                 ]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seeing above some invoices stated ALL_PAID and PAID are also funded_amount NaN\n",
    "# Check The NaN fields\n",
    "len(invoices_claims_last_actived[(invoices_claims_last_actived['funded_amount'].isna())\n",
    "                               & (invoices_claims_last_actived['invoice_state'] == 'ALL_PAID')\n",
    "                               & (invoices_claims_last_actived['claim_state'] == 'PAID')\n",
    "                                ]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_funded_amount =  invoices_claims_last_actived[(invoices_claims_last_actived['funded_amount'].isna())\n",
    "                                                    & (invoices_claims_last_actived['invoice_state'] == 'ALL_PAID')\n",
    "                                                    & (invoices_claims_last_actived['claim_state'] == 'PAID')\n",
    "                                                     ]\n",
    "\n",
    "# Fixes The funded_amount NaN in invoice_state = ALL_PAID and claim_state = PAID\n",
    "df_null_funded_amount['funded_amount'] = df_null_funded_amount['claimed_unit_price'].astype(float) * df_null_funded_amount['claimed_units'].astype(float)\n",
    "\n",
    "invoices_claims_last_actived = invoices_claims_last_actived.set_index('claim_id')\n",
    "invoices_claims_last_actived.update(df_null_funded_amount.set_index('claim_id'))\n",
    "invoices_claims_last_actived.reset_index(inplace=True)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_actived['updated_at'] = pd.to_datetime(invoices_claims_last_actived['updated_at']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the invoices from their claims\n",
    "invoices_claims_last_actived_cleased = invoices_claims_last_actived.groupby([\"member_id\"\n",
    "                                                                           , \"invoice_state\"\n",
    "                                                                           , \"updated_at\"\n",
    "                                                                           , \"claim_state\"\n",
    "                                                                           , \"claim_level1_key\"\n",
    "                                                                           , \"claim_level2_key\"\n",
    "                                                                           , \"claim_level3_key\"]).agg({\"invoiced_amount\": \"sum\", \"funded_amount\": \"sum\"}).reset_index()"
   ]
  },
  {
   "source": [
    "### Invoice and claims dataset From LAST COMPLETED plan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataSet fields\n",
    "invoices_claims_last_completed_all_fields.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_completed_all_fields.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the fields to be used\n",
    "invoices_claims_last_completed = invoices_claims_last_completed_all_fields[{\"member_id\"\n",
    "                                                                          , \"invoice_state\"\n",
    "                                                                          , \"invoice_id\"\n",
    "                                                                          , \"updated_at\"\n",
    "                                                                          , \"claim_state\"\n",
    "                                                                          , \"claim_id\"\n",
    "                                                                          , \"key\"  \n",
    "                                                                          , \"key.1\"\n",
    "                                                                          , \"key.2\"\n",
    "                                                                          , \"claim_start_date\"\n",
    "                                                                          , \"claim_end_date\"\n",
    "                                                                          , \"claim_funded_amount\"\n",
    "                                                                          , \"invoiced_amount\"\n",
    "                                                                          , \"claimed_units\"\n",
    "                                                                          , \"claimed_unit_price\"\n",
    "                                                                      }]\n",
    "\n",
    "# Rename some dataSet colums to create a name's pattern\n",
    "invoices_claims_last_completed.rename(columns={'claim_funded_amount':'funded_amount'\n",
    "                                             , 'claimed__units_price':'claimed__units_amount'  \n",
    "                                             , 'key.1':'claim_level2_key'\n",
    "                                             , 'key.2':'claim_level1_key'\n",
    "                                             , 'key':'claim_level3_key'\n",
    "                                              } , inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the claim_state To check whether there is any dump value\n",
    "invoices_claims_last_completed['claim_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the claim_state To check whether there is any dump value\n",
    "invoices_claims_last_completed['invoice_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any Nan Field\n",
    "print(plotNaNValuesColums(invoices_claims_last_completed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some invoiced_amount and invoiced_amount NaN Data to\n",
    "#  Check these data have in commum\n",
    "df_invoiced_units_NaN = invoices_claims_last_completed.loc[invoices_claims_last_completed['funded_amount'].isna()]\n",
    "df_invoiced_units_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_funded_amount =  invoices_claims_last_completed[(invoices_claims_last_completed['funded_amount'].isna())\n",
    "                                                      & (invoices_claims_last_completed['invoice_state'] == 'ALL_PAID')\n",
    "                                                      & (invoices_claims_last_completed['claim_state'] == 'PAID')\n",
    "                                                     ]\n",
    "\n",
    "# Fixes The funded_amount NaN in invoice_state = ALL_PAID and claim_state = PAID\n",
    "df_null_funded_amount['funded_amount'] = df_null_funded_amount['claimed_unit_price'].astype(float) * df_null_funded_amount['claimed_units'].astype(float)\n",
    "\n",
    "\n",
    "invoices_claims_last_completed = invoices_claims_last_completed.set_index('claim_id')\n",
    "invoices_claims_last_completed.update(df_null_funded_amount.set_index('claim_id'))\n",
    "invoices_claims_last_completed.reset_index(inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the state of invoice and claim of all null data\n",
    "#  And Keeps these records\n",
    "#   Because if 'funded_amount' is NaN means the claims is not PAID OR REFUNDED\n",
    "df_invoiced_units_NaN[{\"invoice_state\"\n",
    "                     , \"claim_state\"\n",
    "                      }].groupby([\"invoice_state\"\n",
    "                                , \"claim_state\"\n",
    "                                 ]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seeing above some invoices stated ALL_PAID and PAID are also funded_amount NaN\n",
    "# Check The NaN fields\n",
    "len(invoices_claims_last_completed[(invoices_claims_last_completed['funded_amount'].isna())\n",
    "                                 & (invoices_claims_last_completed['invoice_state'] == 'ALL_PAID')\n",
    "                                 & (invoices_claims_last_completed['claim_state'] == 'PAID')\n",
    "                                ]\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_last_completed['updated_at'] = pd.to_datetime(invoices_claims_last_completed['updated_at']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the invoices from their claims\n",
    "invoices_claims_last_completed_cleased = invoices_claims_last_completed.groupby([\"member_id\"\n",
    "                                                                               , \"invoice_state\"\n",
    "                                                                               , \"updated_at\" \n",
    "                                                                               , \"claim_state\"\n",
    "                                                                               , \"claim_level1_key\"\n",
    "                                                                               , \"claim_level2_key\"\n",
    "                                                                               , \"claim_level3_key\"]).agg({\"invoiced_amount\": \"sum\", \"funded_amount\": \"sum\"}).reset_index()"
   ]
  },
  {
   "source": [
    "### Merge dataSets cleased"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Merges members dataSet with plans and budgets dataSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Member dataSet with plans and budgets dataSet\n",
    "df_members_plans_budgets_merged = pd.merge(df_members_cleased, df_plans_budgets_cleased, on=[\"member_key\", \"member_key\"])"
   ]
  },
  {
   "source": [
    "### Merges last PLAN_DELIVERY_ACTIVED plan with members plans budgets merged dataSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_plan_delivery_active = df_members_plans_budgets_merged.loc[(df_members_plans_budgets_merged['plan_status'] == 'PLAN_DELIVERY_ACTIVE')]\n",
    "\n",
    "invoices_claims_plan_delivery_active = invoices_claims_plan_delivery_active.merge(invoices_claims_last_actived_cleased, on='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_plan_delivery_active = invoices_claims_plan_delivery_active[\n",
    "\n",
    "   (\n",
    "      (invoices_claims_plan_delivery_active.budget_level3_key == 'Not Assigned')\n",
    "    & (invoices_claims_plan_delivery_active.budget_level2_key == invoices_claims_plan_delivery_active.claim_level2_key)\n",
    "    \n",
    "   )\n",
    "\n",
    "   |\n",
    "\n",
    "   (\n",
    "      (invoices_claims_plan_delivery_active.budget_level3_key != 'Not Assigned')\n",
    "    & (invoices_claims_plan_delivery_active.budget_level3_key == invoices_claims_plan_delivery_active.claim_level3_key)\n",
    "    & (invoices_claims_plan_delivery_active.budget_level2_key == invoices_claims_plan_delivery_active.claim_level2_key)\n",
    "    & (invoices_claims_plan_delivery_active.budget_level1_key == invoices_claims_plan_delivery_active.budget_level1_key)\n",
    "   )\n",
    "\n",
    "       \n",
    "]"
   ]
  },
  {
   "source": [
    "### Merges last COMPLETED plan with members plans budgets merged dataSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_plan_completed = df_members_plans_budgets_merged.loc[(df_members_plans_budgets_merged['plan_status'] == 'COMPLETED')]\n",
    "\n",
    "invoices_claims_plan_completed = invoices_claims_plan_completed.merge(invoices_claims_last_completed_cleased, on='member_id')\n",
    "\n",
    "invoices_claims_plan_completed = invoices_claims_plan_completed[\n",
    "\n",
    "   (\n",
    "      (invoices_claims_plan_completed.budget_level3_key == 'Not Assigned')\n",
    "    & (invoices_claims_plan_completed.budget_level2_key == invoices_claims_plan_completed.claim_level2_key)\n",
    "    \n",
    "   )\n",
    "\n",
    "   |\n",
    "\n",
    "   (\n",
    "      (invoices_claims_plan_completed.budget_level3_key != 'Not Assigned')\n",
    "    & (invoices_claims_plan_completed.budget_level3_key == invoices_claims_plan_completed.claim_level3_key)\n",
    "    & (invoices_claims_plan_completed.budget_level2_key == invoices_claims_plan_completed.claim_level2_key)\n",
    "    & (invoices_claims_plan_completed.budget_level1_key == invoices_claims_plan_completed.budget_level1_key)\n",
    "   )\n",
    "        \n",
    "]"
   ]
  },
  {
   "source": [
    "### Merges last COMPLETED plan dataSet with PLAN_DELIVERY_ACTIVED plan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [invoices_claims_plan_delivery_active, invoices_claims_plan_completed]\n",
    "invoices_claims_merged = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_claims_merged.rename(columns={'invoiced_amount':'requested_amount'\n",
    "                                      } , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = invoices_claims_merged.groupby([\"member_key\"\n",
    "                                         , \"updated_at\"\n",
    "                                         , \"first_name\"\n",
    "                                         , \"last_name\"\n",
    "                                         , \"disabilities\"\n",
    "                                         , \"SA1\"\n",
    "                                         , \"price_zone_code\"                                         \n",
    "                                         , \"plan_key\"\n",
    "                                         , \"plan_status\"\n",
    "                                         , \"plan_start_date\"\n",
    "                                         , \"plan_end_date\"                                                                               \n",
    "                                         , \"budget_level3_name\"\n",
    "                                         , \"budget_level3_key\"\n",
    "                                         , \"budget_level2_key\"\n",
    "                                         , \"budget_level2_name\"\n",
    "                                         , \"budget_level1_key\"\n",
    "                                         , \"budget_level1_name\"                                         \n",
    "                                         , \"invoice_state\"\n",
    "                                         , \"claim_state\"\n",
    "                                         , \"budget_amount\"\n",
    "                                          ]).agg({\"requested_amount\": \"sum\", \"funded_amount\": \"sum\"}).reset_index()                                                          "
   ]
  },
  {
   "source": [
    "### MACHINE LEARNING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNDED AMOUNT\n",
    "funded_amount_from_planStart_to_today = df_model.loc[df_model['updated_at'].between(df_model['plan_start_date'], date.today().strftime(\"%Y-%m-%d\"), inclusive=True)].groupby([\"member_key\"\n",
    "                                                                                                                                                                            , \"first_name\"\n",
    "                                                                                                                                                                            , \"last_name\"\n",
    "                                                                                                                                                                             ]).agg({\"funded_amount\": \"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daysStartPlanTillToday and daysMissingFinishPlan\n",
    "budget_amount_per_member = df_model.loc[df_model['plan_status'] == 'PLAN_DELIVERY_ACTIVE'].groupby([\"member_key\"\n",
    "                                                                                                  , \"plan_start_date\"  \n",
    "                                                                                                  , \"plan_end_date\"]).agg({\"budget_amount\": \"sum\"}).reset_index()\n",
    "\n",
    "\n",
    "budget_amount_per_member['days_start_plan_till_today'] = (pd.to_datetime(date.today().strftime(\"%Y-%m-%d\")) - pd.to_datetime(budget_amount_per_member['plan_start_date'])).dt.days\n",
    "budget_amount_per_member['days_missing_to_finish_Plan'] = (pd.to_datetime(budget_amount_per_member['plan_end_date']) - pd.to_datetime(date.today().strftime(\"%Y-%m-%d\"))).dt.days\n",
    "\n",
    "\n",
    "budget_amount_per_member.rename(columns={'budget_amount':'budget_amount_total'                               \n",
    "                                        } , inplace = True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_amount_per_member = budget_amount_per_member[{'member_key'\n",
    "                                                   , 'days_start_plan_till_today' \n",
    "                                                   , 'days_missing_to_finish_Plan'\n",
    "                                                   , 'budget_amount_total'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_amount_from_planStart_to_today.rename(columns={'funded_amount':'funded_amount_from_start_plan_till_today'\n",
    "                                                      } , inplace = True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE THEM\n",
    "df_model_ML = pd.merge(funded_amount_from_planStart_to_today, budget_amount_per_member, on=[\"member_key\", \"member_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_ML.loc[df_model_ML['member_key'] == '00109970-7029-11eb-81d6-9d4df94b6224']"
   ]
  }
 ]
}